{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a simple content based recommender.\n",
    "Also, uses the MovieLens dataset (actually a sub-set of that dataset downloaded from Kaggle).\n",
    "\n",
    "This system is used to recommend to other movies that are similar to particular movie. This is achieved by computing pairwise cosine similarity scores for all movies based on their plot descriptions, and recommending movies based on that similarity score threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Led by Woody, Andy's toys live happily in his ...\n",
       "1    When siblings Judy and Peter discover an encha...\n",
       "2    A family wedding reignites the ancient feud be...\n",
       "3    Cheated on, mistreated and stepped on, the wom...\n",
       "4    Just when George Banks has recovered from his ...\n",
       "Name: overview, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load movies metadata\n",
    "metadata = pd.read_csv(\"../data/external/movies_metadata.csv\", low_memory=False)\n",
    "\n",
    "# Print plot overview of the movie at head of dataframe\n",
    "metadata['overview'].head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, it is not possible to compute the similarity between any two overviews in their raw forms. In order to do anything mathematical with the overviews, we first compute the word vectors of each overview (also referred to as 'document').\n",
    "\n",
    "Word vectors are vectorized representation of words in a document. These vectors carry a semantic meaning with it. The specific computation applied here is Term Frequency-Inverse Document Frequency (TF-IDF). The TF-IDF score is the frequency of a word occuring in a document, down-weighted by the number of documents in which it occurs. This reduces the importance of words that frequently occur in plot overviews and, therefore their significance in computing the final similarity score.\n",
    "\n",
    "Scikit-learn package provides a built-in TfldfVectorizer class that produces the TF-IDF matrix in a couple of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45466, 75827)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Define TF-IDF vectorizer object. Remove all english stop words such as 'the', 'a'ArithmeticError\n",
    "tfidf = TfidfVectorizer(stop_words='english', dtype=np.float32)\n",
    "\n",
    "# Replace NaN with empty string\n",
    "metadata['overview'] = metadata['overview'].fillna('')\n",
    "\n",
    "# Construct the required TF-IDF matric by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(metadata['overview'])\n",
    "\n",
    "tfidf_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['period', 'periodic', 'periodical', 'periodically', 'periods',\n",
       "       'peripatetic', 'peripheral', 'periphery', 'perish', 'perished'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array mapping from feature integer indices to feature names\n",
    "tfidf.get_feature_names_out()[50000:50010]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incidentally, there are a total of 75827 different words in our movies dataset!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the tftdf_matrix in hand, we can compute the cosine similarity scores. There a number of similarity scores that could be used here -- manhattan, euclidean, the Pearson, etc. Different scores work well in different scenarios.\n",
    "\n",
    "Since we have used the TF-IDF vectorizer, calculating the dot product between each vector will directly give us the cosine similarity score. We will use sklearn's linear_kernel() instead of cosine_similarity(), since it is faster.\n",
    "\n",
    "This would return a matrix of shape 45466x45466, which means each movie overview similarity score with every other movies overview. Hence, each movie will be a 1x45466 column vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfidf_matrix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01504121, 1.0000001 , 0.04681952, ..., 0.        , 0.0219864 ,\n",
       "       0.00929411], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "cosine_sim.shape\n",
    "\n",
    "cosine_sim[1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add a function that takes a movie title as input, and outputs a list of the 10 most similar movies. For this, first we need a reverse mapping from DataFrame index to movie title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Toy Story                      0\n",
       "Jumanji                        1\n",
       "Grumpier Old Men               2\n",
       "Waiting to Exhale              3\n",
       "Father of the Bride Part II    4\n",
       "Heat                           5\n",
       "Sabrina                        6\n",
       "Tom and Huck                   7\n",
       "Sudden Death                   8\n",
       "GoldenEye                      9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()\n",
    "\n",
    "indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def get_recommendation(title, cosine_sim=cosine_sim):\n",
    "    # Get index of the movie that matches the titles\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwise similarity scores of all movies with the input movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movie titles\n",
    "    return metadata['title'].iloc[movie_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12481                                      The Dark Knight\n",
       "150                                         Batman Forever\n",
       "1328                                        Batman Returns\n",
       "15511                           Batman: Under the Red Hood\n",
       "585                                                 Batman\n",
       "21194    Batman Unmasked: The Psychology of the Dark Kn...\n",
       "9230                    Batman Beyond: Return of the Joker\n",
       "18035                                     Batman: Year One\n",
       "19792              Batman: The Dark Knight Returns, Part 1\n",
       "3095                          Batman: Mask of the Phantasm\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_movies = get_recommendation('The Dark Knight Rises')\n",
    "\n",
    "list_of_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2874           Licence to Kill\n",
       "37440               Dream Work\n",
       "2875          Live and Let Die\n",
       "7330                 Octopussy\n",
       "7329       You Only Live Twice\n",
       "8331                  Doctor X\n",
       "7333     Never Say Never Again\n",
       "37934      Johnny Stool Pigeon\n",
       "5658             Casino Royale\n",
       "4316     The Way of the Dragon\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendation('GoldenEye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1178               The Godfather: Part II\n",
       "44030    The Godfather Trilogy: 1972-1990\n",
       "1914              The Godfather: Part III\n",
       "23126                          Blood Ties\n",
       "11297                    Household Saints\n",
       "34717                   Start Liquidation\n",
       "10821                            Election\n",
       "38030            A Mother Should Be Loved\n",
       "17729                   Short Sharp Shock\n",
       "26293                  Beck 28 - Familjen\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendation('The Godfather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26594       I Don't Buy Kisses Anymore\n",
       "27337                Robin of Locksley\n",
       "34887               Starring Adam West\n",
       "35930                  Poil de Carotte\n",
       "41416                           Hunted\n",
       "24588                       Chatterbox\n",
       "43426    Robin Williams - Off the Wall\n",
       "18999                           Bernie\n",
       "28207                The Boy Next Door\n",
       "2141                              Hero\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendation('Waiting to Exhale')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
